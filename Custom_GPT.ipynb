{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGO9u9BnJQG+EOI0+9i0Ov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harbidel/Custom-GPT/blob/main/Custom_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing Excel sheet using GPT"
      ],
      "metadata": {
        "id": "J2g8DAoJlqAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " it is possible for GPT to analyze an Excel sheet. However, it would typically require preprocessing the data in the Excel sheet into a format that can be used for training or fine-tuning a language model. For example, you could convert the data into a text file with a specific format, such as a CSV file or a JSON file, and then use that file as input to the language model.\n",
        "\n",
        "Once the data has been preprocessed and formatted in a way that can be used for training, you can fine-tune a language model such as GPT-3 on the data to make predictions or generate text based on the information in the Excel sheet.\n",
        "\n",
        "Keep in mind that this process can be quite complex, especially if the data in the Excel sheet is unstructured or requires extensive preprocessing. You may need to write custom code to convert the data into a usable format and to fine-tune the language model on the data."
      ],
      "metadata": {
        "id": "SqB8w9LUle-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Note: This code is just a prototype to solve this particular challenge"
      ],
      "metadata": {
        "id": "PCx72Y9RW5YW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the Excel sheet:"
      ],
      "metadata": {
        "id": "RzstwQZ-k8UN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laJlGZHCk6YZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the Excel sheet into a pandas DataFrame\n",
        "df = pd.read_excel(\"data.xlsx\")\n",
        "\n",
        "# Convert the DataFrame to a CSV file\n",
        "df.to_csv(\"data.csv\", index=False)\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Preprocess the data as needed\n",
        "...\n",
        "\n",
        "# Save the preprocessed data to a text file\n",
        "with open(\"data.txt\", \"w\") as f:\n",
        "    for row in df.itertuples():\n",
        "        # Write each row of preprocessed data to the file\n",
        "        f.write(str(row) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning the language model:"
      ],
      "metadata": {
        "id": "zvJQMG0ZlBv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "# Load the pre-trained language model\n",
        "model = transformers.AutoModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Prepare the data for fine-tuning\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "input_ids = tokenizer.encode(open(\"data.txt\").read(), return_tensors=\"pt\")\n",
        "\n",
        "# Fine-tune the model on the data\n",
        "...\n"
      ],
      "metadata": {
        "id": "ajPlauWJlAxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this is just a simple example and you may need to make significant modifications to the code to fit your specific use case and requirements. Also, keep in mind that fine-tuning a language model can be a complex and time-consuming process, especially for large models like GPT-3."
      ],
      "metadata": {
        "id": "yYthNC2tlZJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to fine-tune GPT-3 on a dataset of local text data using the OpenAI API:"
      ],
      "metadata": {
        "id": "KmznMOYLlNVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"YOUR_API_KEY\"\n",
        "\n",
        "# Load your local text data\n",
        "with open(\"data.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Fine-tune the GPT-3 model on the local text data\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=\"Fine-tune GPT-3 on local data: \" + text,\n",
        "    max_tokens=1024,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    temperature=0.5,\n",
        ")\n",
        "\n",
        "# Get the generated completion\n",
        "completion = response[\"choices\"][0][\"text\"]\n",
        "\n",
        "print(\"Generated completion: \" + completion)\n"
      ],
      "metadata": {
        "id": "pMb6T8lblAyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code fine-tunes the \"davinci\" version of GPT-3 on the local text data by sending a request to the OpenAI API. The prompt argument is the text that you want GPT-3 to complete, and the max_tokens argument is the maximum number of tokens (words or subwords) that GPT-3 should generate in its completion. The n argument is the number of completions you want to generate, and the stop argument is an optional string that you can use to specify a stop token that will cause GPT-3 to stop generating tokens after it encounters this token. The temperature argument is a value that controls the randomness of the generated tokens, with higher values resulting in more random completions and lower values resulting in more deterministic completions."
      ],
      "metadata": {
        "id": "JM2tcnn1lR9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here's a basic implementation of a chatbot that uses GPT-3 to answer questions about data in an Excel sheet, using Python:"
      ],
      "metadata": {
        "id": "--WwyDaWnIlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "# Load your Excel sheet into a pandas dataframe\n",
        "df = pd.read_excel(\"data.xlsx\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2VdEYgQnKwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "openai.api_key = \"YOUR_API_KEY\""
      ],
      "metadata": {
        "id": "4csz98vtnhuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get an API key for OpenAI's GPT-3, you need to sign up for an OpenAI account on their website (https://beta.openai.com/). Once you have an account, you can access your API key in the \"API Key\" section of your account settings.\n",
        "\n",
        "Note that OpenAI's GPT-3 is currently in private beta and access is limited. You may need to wait for a spot to open up in order to get an API key. Additionally, using the GPT-3 API may incur charges, so be sure to familiarize yourself with their pricing and usage policies before using the API in your project."
      ],
      "metadata": {
        "id": "Q4-UF6DHn391"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI offers several APIs for different use cases, including GPT-3. The API key you should use for your project will depend on the specific requirements of your project.\n",
        "\n",
        "For example, if you're using GPT-3 to generate text completions and answers to questions, as in the chatbot example I provided earlier, you'll likely want to use OpenAI's Completion API. This API provides fine-tuned language models that you can use to generate completions for text inputs.\n",
        "\n",
        "For more information on the different OpenAI APIs and their features and pricing, you can visit the OpenAI website (https://beta.openai.com/docs/apis). Additionally, you may want to consider reaching out to the OpenAI support team for assistance in selecting the best API for your project."
      ],
      "metadata": {
        "id": "E6ofy5mdoHR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a response to a user's query\n",
        "def generate_response(query):\n",
        "    # Fine-tune the GPT-3 model on the user's query\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\",\n",
        "        prompt=query,\n",
        "        max_tokens=1024,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0.5,\n",
        "    )\n",
        "\n",
        "    # Get the generated completion\n",
        "    completion = response[\"choices\"][0][\"text\"]\n",
        "\n",
        "    # Process the generated completion to extract the answer\n",
        "    answer = completion.strip()\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "kX_k7NcSnYdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle user inputs and generate responses\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Excel Data Chatbot! You can ask me questions about the data in the Excel sheet.\")\n",
        "\n",
        "    # Loop to handle multiple user inputs\n",
        "    while True:\n",
        "        query = input(\"Ask me a question: \")\n",
        "\n",
        "        # Check if the user wants to exit the chatbot\n",
        "        if query.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Exiting the chatbot. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Generate a response to the user's query\n",
        "        response = generate_response(query)\n",
        "\n",
        "        # Print the response\n",
        "        print(\"Answer: \" + response)\n",
        "\n",
        "# Start the chatbot\n",
        "chatbot()"
      ],
      "metadata": {
        "id": "ERXa1O7pnLAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses the pandas library to load an Excel sheet into a dataframe, and then uses the OpenAI API to fine-tune the GPT-3 model on user queries. The generate_response function takes a user query as input and fine-tunes the GPT-3 model on the query to generate a completion, which is then processed to extract the answer. The chatbot function handles user inputs and generates responses using the generate_response function, until the user decides to exit the chatbot."
      ],
      "metadata": {
        "id": "FFpht0crnLQf"
      }
    }
  ]
}